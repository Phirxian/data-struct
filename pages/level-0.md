<h1 class="text-center" style="position: relative;top: 50%;">Niveau 0</h1>
<p class="text-center" style="position: relative;top: 50%;">Comprendre la complexit√©</p>

---
transition: fade-out
---
# Introduction
Pourquoi est-elle essentielle dans le d√©veloppement logiciel ?

**Objectifs de cette pr√©sentation :**
- D√©finir la complexit√© des algorithmes
- Expliquer les notations asymptotiques (O, Œ©, Œò)
- Discuter de l'importance des constantes dans ces notations
- Pr√©senter des exemples pratiques en pseudo-C

**Pourquoi est-ce important ?**
- Optimisation des performances (CPU vs RAM)
- Provisionn√© vos ressources (contrainte mat√©riel)
- Am√©lioration de la qualit√© du code

---
transition: fade-out
---
# D√©finition de la complexit√© des algorithmes
Mesurer l'Efficacit√© des Programmes

La complexit√© d'un algorithme est une mesure de la quantifir les ressources n√©cessite pour traiter une donn√©e.
Elle nous permet de pr√©dire comment l'algorithme se comportera lorsque la taille des donn√©es augmente.

**Types de Complexit√© :**
- **Complexit√© Temporelle** : Temps n√©cessaire pour ex√©cuter l'algorithme (CPU).
- **Complexit√© Spatiale** : Espace m√©moire n√©cessaire pour ex√©cuter l'algorithme (RAM).

**Pourquoi est-elle importante ?**
- **Optimisation des performances** : Am√©liorer la rapidit√© et l'efficacit√©.
- **√âvolutivit√©** : Pr√©voir comment l'algorithme se comportera avec des donn√©es plus volumineuses.
- **Qualit√© du code** : √âcrire des programmes plus efficaces et maintenables.

**Similariter**
- Pour faire simple compter le nombre d'op√©ration quand : $\lim_{n\rightarrow+\infty}f(n)$

---
transition: fade-out
---
**Exemple simple :**

Supposons un algorithme de recherche dans une liste de n √©l√©ments.

Voici un pseudo-algo qui v√©rifie un par un les √©l√©ments de la liste pour le trouver
```cpp
int recherche(int *array, size_t size, int value) {
    int index = -1;
    for (size_t i=0; i<size; ++i)
        if (array[i] == value)
            index = i;
    return index;
}
```

Cette algorithm a une complexit√© temporel lineaire, 
dans tout les cas le temps d'√©x√©cution d'√©pendra de la taille de `@array`.

---
transition: fade-out
---

# Notations asymptotiques

Les notations asymptotiques sont utilis√©es pour d√©crire la complexit√© d'un algorithme en fonction de la taille de l'entr√©e. Elles nous aident √† pr√©dire comment l'algorithme se comportera lorsque la taille des donn√©es augmente.

**Big O**
- **D√©finition :** Limite sup√©rieure. C'est la pire des situations.
- **Interpr√©tation :** L'algorithme ne prendra jamais plus de temps que O(n) pour une liste de n √©l√©ments.

**Big Œ©** (parfois minus o)
- **D√©finition :** Limite inf√©rieure. C'est la meilleure des situations.
- **Interpr√©tation :** L'algorithme prendra au minimum Œ©(n) temps pour une liste de n √©l√©ments.

**Big Œò**
- **D√©finition :** Limite exacte √† la complexit√© d'un algorithme. Quand **O(f)=Œ©(f)**
- **Interpr√©tation :** L'algorithme prend exactement Œò(n) temps pour une liste de n √©l√©ments.

---
transition: fade-out
---

<center>
<img src="/snippets/image-18.png" width="50%"/>
</center>

- üöÄ Complexit√© constante **O(1)** 
- üöÇ Complexit√© logarithmique **O(log(n))**
- üöó Complexit√© lin√©aire **O(n)**
- üìà Complexit√© quasi-lin√©aire **O(n ‚ãÖ log(n))**
- ‚ö†Ô∏è Complexit√© quadratique **O(n¬≤)**
- üöß Complexit√© exponentielle **O(2n)**
- üö® Complexit√© factorielle **O(n!)**

---
transition: fade-out
---

# Notation asymptotiques et approximation

Dans la notation asymptotique, on oublie les termes constants

- O(2n) = O(n) : Les constantes sont ignor√©es, donc multiplier par 2 ne change "pas" la complexit√©.
- O(3n¬≤) = O(n¬≤) : De m√™me, les constantes devant les puissances sont ignor√©es.
- O(n + 10) = O(n) : Les termes constants sont n√©glig√©s par rapport aux termes variables.
- O(n¬≤ + n) = O(n¬≤) : Dans les polyn√¥mes, on ne garde que le terme dominant.

Pourquoi ignorer les constantes ?
- **√âchelle de grandeur :** Lorsque la taille des donn√©es augmente, les constantes deviennent n√©gligeables par rapport √† la croissance globale.
- **Mod√©lisation simplifi√©e :** Ignorer les constantes simplifie l'analyse et permet de se concentrer sur la tendance g√©n√©rale.

---
transition: fade-out
---

# Attention

> Ses notions sont a savoir et utilis√©es dans les tests de recrutement,
mais c'est fondamentalement incorrect !

Pourquoi les constantes sont-elles importantes ?
- **Performances r√©elles :** Dans la pratique, les constantes peuvent avoir un impact significatif sur les performances, surtout si elles repr√©sentent des op√©rations complexes ou des acc√®s m√©moire co√ªteux.
- **Optimisation :** Ignorer les constantes peut conduire √† n√©gliger des opportunit√©s d'optimisation importantes. Par exemple, un algorithme avec une constante plus petite mais une complexit√© similaire est plus rapide en pratique.
- **Cas r√©els :** Dans de nombreux cas r√©els, les tailles des donn√©es ne sont pas toujours tr√®s grandes, et les constantes peuvent donc jouer un r√¥le crucial dans la performance globale.
- **Taille des donn√©es :** Si la notation Big O ce concentre sur de large √©chelles de donn√©e, en pratique vous connaitrez presque toujours les tailles. Elles seront presque toujours petites dans ce cas un algorithme en O(n) peut √™tre meilleur qu'un algorithm en O(log(n))'

---
transition: fade-out
---

<iframe width="800" height="500" src="https://www.youtube.com/embed/gCzOhZ_LUps" title="What Big-O notation ACTUALLY tells you, and how I almost failed my Google Interview" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---
transition: fade-out
---

# Exemples de complexit√© en Œò(1)
_

Toute op√©ration qui accede directement a une donn√©e:

```cpp
int tableau[1000];
int index = 5;
int valeur = tableau[index];
```

ou effectue des calcules

```cpp
bool estPair(int nombre) {
  return nombre % 2 == 0;
}
```

<br>

- Ceci n'est pas vrais pour certaines structures de donn√©es complexe (hash map, bin tree, etc) "cach√©"
- Quelle complexit√© est cach√© pour la fonction estPair ?

---
transition: fade-out
---

## Quelle est la complexit√© de ce code ?

<br>

- Complexit√© spatial ?
- Complexit√© temporel ?

<br>

```cpp
int x = 3;
int n = 10;
int result = pow(x, n) * sqrt(x, n);
```

<br>

- **A** : Œò(1)
- **B** : Œò(2)
- **C** : On ne sait pas ?
- **D** : Expliquer

---
transition: fade-out
---

# Exemples de complexit√© en Œò(n)

```cpp
double pow(double base, int exponent) {
  double result = 1.0;
  for (int i = 0; i < exponent; i++) {
    result *= base;
  }
  return result;
}
```

```cpp
int recherche(int *array, size_t size, int value) {
    int index = -1;
    for (size_t i=0; i<size; ++i)
        if (array[i] == value)
            index = i;
    return index;
}
```

---
transition: fade-out
---

## Quelle est la complexit√© de ce code ?

<br>

```cpp
int recherche(int *array, size_t size, int value) {
  for (size_t i=0; i<size; ++i)
    if (array[i] == value)
      return i;
  return -1;
}
```

<br>
  
- Complexit√© spatial ?
  - **A**:  O(1)
  - **B**:  Œò(1)
  - **C**:  Œ©(1)
- Complexit√© temporel ?
  - **A**:  O(n)
  - **B**:  Œò(n)
  - **C**:  Œ©(1) et O(n)

---
transition: fade-out
---

# Exemples de complexit√© en Œò(log(n))

```cpp
double pow(double base, int exponent) {
    double result = 1.0;
    
    while (exponent > 0) {
        if (exponent % 2 == 1)
            result *= base;
        exponent /= 2;
        base *= base;
    }
    
    return result;
}
```

---
transition: fade-out
---
# Exemples de complexit√© en Œò(log(n))

```cpp
double sqrt(double x) {
    if (x < 0)
        return NAN;
    else if (x == 0 || x == 1)
        return x;

    double guess = x / 2.0;
    double precision = 0.000001;

    while (1) {
        double betterGuess = (guess + x / guess) / 2.0;
        if (fabs(guess - betterGuess) < precision)
            return betterGuess;
        guess = betterGuess;
    }
}
```
<br>

## Peut-on faire mieux ?

---
transition: fade-out
---

# John Carmack et Quake III

```cpp
float fast_sqrt(float number) {
    long i;
    float x2, y;
    const float threehalfs = 1.5F;

    y = number;
    i = *(long*)&y;
    i = 0x5f3759df - (i >> 1); 
    y = *(float*)&i;

    y = y * (threehalfs - (x2 = number * 0.5F) * y * y);
    y = y * (threehalfs - (x2 = number * 0.5F) * y * y);
    
    return 1/y;
}
```

https://en.wikipedia.org/wiki/Fast_inverse_square_root

---
transition: fade-out
---
# Exemples de complexit√© en Œò(n^2)

```cpp
double pow(double base, int exponent) {
    double result = 1.0;
    
    for (int i = 0; i < exponent; i++)
        for (int j = 0; j < exponent; j++)
            if (i == j)
                result *= base;
                
    return result;
}
```

<br>

> Attention, le compilateur passe par l√† et fait aussi des optimisations ! (-Ofast -O3 -Og) ;)